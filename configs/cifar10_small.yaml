data:
  name: cifar10
  batch_size: 32
  num_workers: 8
  shuffle: true
  cache: true
  split_train: "train[:95%]"
  split_eval: "test"

model:
  in_ch: 3
  latent_hw: 32
  ch: 64                # Base channels
  ch_mult: [1, 2, 4]    # Channel multipliers: [64, 128, 256]
  num_res_blocks: 2     # Residual blocks per level
  num_classes: 10

time:
  schedule: linear     # a_t=1-t, b_t=t
  sampler: uniform_pair

train:
  epochs: 10
  lr: 6.0e-4 # Learning rate should be 0.0006
  wd: 0.0
  ema: 0.99995
  grad_clip: 1.0
  cfg_drop: 0.1
  seed: 0

eval:
  nfe: 1
  cfg_scale: 2.0
  log_every: 100
  ckpt_every: 10
